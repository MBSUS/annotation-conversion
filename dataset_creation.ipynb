{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for study in os.listdir(\"Studies/\"):\n",
    "    for orientation in os.listdir(\"Studies/\"+study+\"/\"):\n",
    "        for folder in os.listdir(\"Studies/\"+study+\"/\"+orientation+\"/\"):\n",
    "            if folder == \"anno\":\n",
    "                df = pd.read_csv(\"Studies/\"+study+\"/\"+orientation+\"/\"+folder+\"/gTruth.csv\").dropna().reset_index().drop(columns=\"index\")\n",
    "                df[\"PixelLabelData\"] = df[\"PixelLabelData\"].map(lambda path: \"/\".join([\"Studies\"]+path.split(\"/\")[-5:]))\n",
    "                df[\"OriginalData\"] = \"\"\n",
    "                try:\n",
    "                    os.mkdir(\"Studies/\"+study+\"/\"+orientation+\"/\"+folder+\"/OriginalData/\")\n",
    "                    vidcap = cv2.VideoCapture(\"Studies/\"+study+\"/\"+orientation+\"/clip/\"+orientation+\".mp4\")\n",
    "                    for i in range(len(df)):\n",
    "                        name = df.at[i, 'PixelLabelData'].split(\"/\")[-1]\n",
    "                        time = round(float(df.at[i, 'Time'].split(\" \")[0])*1000)\n",
    "                        vidcap.set(cv2.CAP_PROP_POS_MSEC, time)\n",
    "                        success,image = vidcap.read()\n",
    "                        if success:\n",
    "                            cv2.imwrite(\"Studies/\"+study+\"/\"+orientation+\"/\"+folder+\"/OriginalData/\"+name, image)\n",
    "                            df.at[i, \"OriginalData\"] = \"Studies/\"+study+\"/\"+orientation+\"/\"+folder+\"/OriginalData/\"+name\n",
    "                    df = df.replace('', np.nan).dropna().reset_index().drop(columns=\"index\")\n",
    "                    df.to_csv(\"Studies/\"+study+\"/\"+orientation+\"/\"+\"data.csv\", index=False)\n",
    "                except:\n",
    "                    print(\"folder done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = []\n",
    "for study in os.listdir(\"Studies/\"):\n",
    "    for orientation in os.listdir(\"Studies/\"+study+\"/\"):\n",
    "        for fsobject in os.listdir(\"Studies/\"+study+\"/\"+orientation+\"/\"):\n",
    "            if fsobject == \"data.csv\":\n",
    "                df = pd.read_csv(\"Studies/\"+study+\"/\"+orientation+\"/\"+fsobject)\n",
    "                finaldf.append(df)\n",
    "finaldf = pd.concat(finaldf, ignore_index=True)\n",
    "finaldf.to_csv(\"dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "try:\n",
    "    os.mkdir(\"data/\")    \n",
    "    os.mkdir(\"data/train_frames/\")\n",
    "    os.mkdir(\"data/mask_frames/\")\n",
    "    os.mkdir(\"data/train_frames/train\")\n",
    "    os.mkdir(\"data/mask_frames/mask\")\n",
    "    for i in range(len(dataset)):\n",
    "        image = cv2.imread(dataset.at[i, 'OriginalData'])\n",
    "        mask = cv2.imread(dataset.at[i, 'PixelLabelData'], cv2.IMREAD_GRAYSCALE)\n",
    "        if (sum(sum(mask)) > 0):\n",
    "            cv2.imwrite(\"data/train_frames/train/\"+str(i)+\".png\", image)\n",
    "            cv2.imwrite(\"data/mask_frames/mask/\"+str(i)+\".png\", mask)\n",
    "except:\n",
    "    for i in range(len(dataset)):\n",
    "        image = cv2.imread(dataset.at[i, 'OriginalData'])\n",
    "        mask = cv2.imread(dataset.at[i, 'PixelLabelData'], cv2.IMREAD_GRAYSCALE)\n",
    "        if (sum(sum(mask)) > 0):\n",
    "            cv2.imwrite(\"data/train_frames/train/\"+str(i)+\".png\", image)\n",
    "            cv2.imwrite(\"data/mask_frames/mask/\"+str(i)+\".png\", mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 100 images belonging to 1 classes.\nFound 100 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = train_datagen.flow_from_directory('data/train_frames/', target_size=(512,512), class_mode=None, batch_size=2)\n",
    "train_mask_generator = train_datagen.flow_from_directory('data/mask_frames/', target_size=(512,512), class_mode=None, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(train_image_generator, train_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-net\n",
    "\n",
    "inputs = tf.keras.layers.Input((512,512,3))\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = tf.keras.layers.Dropout(0.5)(conv4)\n",
    "pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = tf.keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = tf.keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = tf.keras.layers.Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = tf.keras.layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = tf.keras.layers.concatenate([drop4,up6], axis = 3)\n",
    "conv6 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = tf.keras.layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = tf.keras.layers.concatenate([conv3,up7], axis = 3)\n",
    "conv7 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = tf.keras.layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = tf.keras.layers.concatenate([conv2,up8], axis = 3)\n",
    "conv8 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = tf.keras.layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = tf.keras.layers.concatenate([conv1,up9], axis = 3)\n",
    "conv9 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = tf.keras.layers.Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv10 = tf.keras.layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 34s 421ms/step - loss: 0.3516 - accuracy: 0.9774\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.99024, saving model to ./weights\n",
      "INFO:tensorflow:Assets written to: ./weights/assets\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 23s 454ms/step - loss: 0.1257 - accuracy: 0.9945\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.99024 to 0.99416, saving model to ./weights\n",
      "INFO:tensorflow:Assets written to: ./weights/assets\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 23s 469ms/step - loss: 0.0520 - accuracy: 0.9944\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.99416 to 0.99416, saving model to ./weights\n",
      "INFO:tensorflow:Assets written to: ./weights/assets\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 23s 463ms/step - loss: 0.0531 - accuracy: 0.9939\n",
      "\n",
      "Epoch 00004: accuracy did not improve from 0.99416\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "NO_OF_TRAINING_IMAGES = len(os.listdir('data/train_frames/train/'))\n",
    "\n",
    "NO_OF_EPOCHS = 30\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "weights_path = './weights'\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(weights_path, monitor='accuracy', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('./log.out', append=True, separator=';')\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', verbose = 1,\n",
    "                              min_delta = 0.01, patience = 3, mode = 'max')\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, earlystopping]\n",
    "\n",
    "results = model.fit(train_generator, epochs=NO_OF_EPOCHS, \n",
    "                          steps_per_epoch = (NO_OF_TRAINING_IMAGES//BATCH_SIZE),\n",
    "                          callbacks=callbacks_list)\n",
    "model.save('Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}