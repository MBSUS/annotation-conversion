{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 80 images belonging to 1 classes.\nFound 80 images belonging to 1 classes.\nFound 20 images belonging to 1 classes.\nFound 20 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_generator = train_datagen.flow_from_directory('data/train_frames/', target_size=(512,512), subset='training', class_mode=None, batch_size=2)\n",
    "train_mask_generator = train_datagen.flow_from_directory('data/mask_frames/', target_size=(512,512), subset='training', class_mode=None, batch_size=2)\n",
    "val_image_generator = train_datagen.flow_from_directory('data/train_frames/', target_size=(512,512), subset='validation', class_mode=None, batch_size=2)\n",
    "val_mask_generator = train_datagen.flow_from_directory('data/mask_frames/', target_size=(512,512), subset='validation', class_mode=None, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "val_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-net\n",
    "\n",
    "inputs = tf.keras.layers.Input((512,512,3))\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "conv1 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "conv2 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "conv3 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = tf.keras.layers.Dropout(0.5)(conv4)\n",
    "pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = tf.keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = tf.keras.layers.Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = tf.keras.layers.Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = tf.keras.layers.Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = tf.keras.layers.concatenate([drop4,up6], axis = 3)\n",
    "conv6 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = tf.keras.layers.Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = tf.keras.layers.Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = tf.keras.layers.concatenate([conv3,up7], axis = 3)\n",
    "conv7 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = tf.keras.layers.Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = tf.keras.layers.Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = tf.keras.layers.concatenate([conv2,up8], axis = 3)\n",
    "conv8 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = tf.keras.layers.Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = tf.keras.layers.Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(tf.keras.layers.UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = tf.keras.layers.concatenate([conv1,up9], axis = 3)\n",
    "conv9 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = tf.keras.layers.Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = tf.keras.layers.Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv10 = tf.keras.layers.Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "model = tf.keras.Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "model.compile(optimizer = tf.optimizers.Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_TRAINING_IMAGES = len(os.listdir('data/train_frames/train/'))\n",
    "\n",
    "NO_OF_EPOCHS = 30\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "weights_path = './weights'\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(weights_path, monitor='accuracy', \n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "csv_logger = tf.keras.callbacks.CSVLogger('./log.out', append=True, separator=';')\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', verbose = 1,\n",
    "                              min_delta = 0.01, patience = 3, mode = 'max')\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, earlystopping]\n",
    "\n",
    "results = model.fit(train_generator, epochs=NO_OF_EPOCHS, \n",
    "                          steps_per_epoch = (NO_OF_TRAINING_IMAGES//BATCH_SIZE),\n",
    "                          validation_data=val_generator,\n",
    "                          callbacks=callbacks_list)\n",
    "model.save('Model.h5')"
   ]
  }
 ]
}